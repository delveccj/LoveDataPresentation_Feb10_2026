{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 1: Load Excel Files from GitHub into DataFrames\n",
    "# ============================================================================\n",
    "\n",
    "%pip install openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "GITHUB_REPO = \"delveccj/LoveDataPresentation_Feb10_2026\"\n",
    "GITHUB_BRANCH = \"main\"\n",
    "\n",
    "YEARS_TO_CONVERT = [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "def load_excel_from_github(year):\n",
    "    filename = f\"{year}-List-of-all-ships-dismantled-all-over-the-world.xlsx\"\n",
    "    url = f\"https://raw.githubusercontent.com/{GITHUB_REPO}/{GITHUB_BRANCH}/{filename}\"\n",
    "    print(f\"Loading {year}...\", end=\" \")\n",
    "    response = requests.get(url, timeout=30)\n",
    "    if response.status_code == 404:\n",
    "        print(\"not found\")\n",
    "        return None\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # 2015+ files have header on a different row\n",
    "    if year >= 2015:\n",
    "        df_peek = pd.read_excel(BytesIO(response.content), dtype=str, engine='openpyxl', nrows=5)\n",
    "        header_row = 0\n",
    "        for idx in range(min(5, len(df_peek))):\n",
    "            row_values = df_peek.iloc[idx].astype(str).str.upper().tolist()\n",
    "            if any(x in str(row_values) for x in ['IMO', 'NAME', 'TYPE', 'LDT', 'BUILT']):\n",
    "                header_row = idx + 1\n",
    "                break\n",
    "        df = pd.read_excel(BytesIO(response.content), dtype=str, engine='openpyxl', header=header_row)\n",
    "    else:\n",
    "        df = pd.read_excel(BytesIO(response.content), dtype=str, engine='openpyxl')\n",
    "    \n",
    "    print(f\"{len(df):,} rows, {len(df.columns)} cols\")\n",
    "    return df\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING DATA FROM GITHUB\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "dataframes = {}\n",
    "for year in YEARS_TO_CONVERT:\n",
    "    df = load_excel_from_github(year)\n",
    "    if df is not None:\n",
    "        dataframes[year] = df\n",
    "\n",
    "print(f\"\\nLoaded {len(dataframes)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore columns - especially owner-related ones\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COLUMN EXPLORATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for year, df in dataframes.items():\n",
    "    print(f\"\\n{year}:\")\n",
    "    print(f\"  All columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 2: Data Integration Pipeline (with Owner data)\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ShipbreakingIntegrator:\n",
    "    \"\"\"Integrates shipbreaking data including beneficial owner information.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.unified_columns = [\n",
    "            'YEAR', 'IMO', 'NAME', 'TYPE', 'GT', 'LDT', \n",
    "            'BUILT', 'LAST_FLAG', 'PLACE', 'COUNTRY',\n",
    "            'OWNER', 'OWNER_COUNTRY'\n",
    "        ]\n",
    "        \n",
    "        self.location_to_country = {\n",
    "            'alang': 'India', 'bhavnagar': 'India', 'sosiya': 'India',\n",
    "            'chittagong': 'Bangladesh', 'bangladesh': 'Bangladesh',\n",
    "            'gadani': 'Pakistan', 'pakistan': 'Pakistan',\n",
    "            'aliaga': 'Turkey', 'aliağa': 'Turkey', 'turkey': 'Turkey',\n",
    "            'ghent': 'Belgium', 'belgium': 'Belgium',\n",
    "            'guangzhou': 'China', 'shanghai': 'China', 'china': 'China',\n",
    "            'india': 'India',\n",
    "        }\n",
    "    \n",
    "    def find_column(self, df, candidates):\n",
    "        \"\"\"Find the first matching column from a list of candidates.\"\"\"\n",
    "        for col in candidates:\n",
    "            if col in df.columns:\n",
    "                return df[col]\n",
    "        return pd.Series([np.nan] * len(df))\n",
    "    \n",
    "    def extract_country_from_place(self, place):\n",
    "        if pd.isna(place) or str(place).strip() == '':\n",
    "            return np.nan\n",
    "        place_lower = str(place).strip().lower()\n",
    "        for loc, country in self.location_to_country.items():\n",
    "            if loc in place_lower:\n",
    "                return country\n",
    "        return np.nan\n",
    "    \n",
    "    def process_year(self, year, df_in):\n",
    "        \"\"\"Process a single year's dataframe into unified schema.\"\"\"\n",
    "        result = pd.DataFrame()\n",
    "        n_rows = len(df_in)\n",
    "        \n",
    "        result['YEAR'] = [year] * n_rows\n",
    "        \n",
    "        # IMO\n",
    "        result['IMO'] = self.find_column(df_in, [\n",
    "            'IMO#', 'IMO  number', 'IMO number', 'IMO'\n",
    "        ])\n",
    "        \n",
    "        # NAME\n",
    "        result['NAME'] = self.find_column(df_in, [\n",
    "            'NAME', 'Name of ship ', 'Name of ship', 'SHIP NAME'\n",
    "        ])\n",
    "        \n",
    "        # TYPE\n",
    "        result['TYPE'] = self.find_column(df_in, [\n",
    "            'TYPE', 'Type of ship', 'SHIP TYPE', 'Type'\n",
    "        ])\n",
    "        \n",
    "        # GT\n",
    "        result['GT'] = self.find_column(df_in, [\n",
    "            'GT', 'Gross tonnage (GT)', 'GROSS TONNAGE'\n",
    "        ])\n",
    "        \n",
    "        # LDT\n",
    "        result['LDT'] = self.find_column(df_in, [\n",
    "            'LDT', 'Ldt (light displacement ton)', 'LDT (TONNES)'\n",
    "        ])\n",
    "        \n",
    "        # BUILT\n",
    "        result['BUILT'] = self.find_column(df_in, [\n",
    "            'BUILT', 'Built in (y)', 'BUILD YEAR', 'Year Built'\n",
    "        ])\n",
    "        \n",
    "        # LAST_FLAG\n",
    "        result['LAST_FLAG'] = self.find_column(df_in, [\n",
    "            'FLAG', 'LAST FLAG', 'Last flag', 'LAST FLAG (CHANGE FOR BREAKING)'\n",
    "        ])\n",
    "        \n",
    "        # PLACE\n",
    "        result['PLACE'] = self.find_column(df_in, [\n",
    "            'PLACE', 'DESTINATION', 'Destination yard', 'Destination city', 'YARD'\n",
    "        ])\n",
    "        \n",
    "        # COUNTRY\n",
    "        country_col = self.find_column(df_in, [\n",
    "            'COUNTRY', 'Destination country', 'DEST. COUNTRY'\n",
    "        ])\n",
    "        if country_col.isna().all():\n",
    "            result['COUNTRY'] = result['PLACE'].apply(self.extract_country_from_place)\n",
    "        else:\n",
    "            result['COUNTRY'] = country_col\n",
    "        \n",
    "        # OWNER (beneficial owner)\n",
    "        result['OWNER'] = self.find_column(df_in, [\n",
    "            'Beneficial owner of the ship', 'BENEFICIAL OWNER', \n",
    "            'BO', 'OWNER', 'Beneficial Owner'\n",
    "        ])\n",
    "        \n",
    "        # OWNER_COUNTRY\n",
    "        result['OWNER_COUNTRY'] = self.find_column(df_in, [\n",
    "            \"Beneficial owner's Country \", 'BO Country ', \n",
    "            'Country of the beneficial owner', 'BO COUNTRY',\n",
    "            'OWNER COUNTRY', 'Beneficial Owner Country'\n",
    "        ])\n",
    "        \n",
    "        return result[self.unified_columns]\n",
    "    \n",
    "    def integrate(self, dataframes_dict):\n",
    "        \"\"\"Integrate all dataframes into a single unified dataset.\"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        for year, df_in in sorted(dataframes_dict.items()):\n",
    "            print(f\"Processing {year}...\", end=\" \")\n",
    "            processed = self.process_year(year, df_in)\n",
    "            \n",
    "            before = len(processed)\n",
    "            processed = processed.dropna(subset=['IMO', 'NAME'], how='all')\n",
    "            after = len(processed)\n",
    "            \n",
    "            all_data.append(processed)\n",
    "            print(f\"{after:,} records\")\n",
    "        \n",
    "        unified = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Convert numeric columns\n",
    "        for col in ['GT', 'LDT', 'BUILT', 'YEAR']:\n",
    "            unified[col] = pd.to_numeric(unified[col], errors='coerce')\n",
    "        \n",
    "        # Clean text columns\n",
    "        for col in ['NAME', 'TYPE', 'LAST_FLAG', 'PLACE', 'COUNTRY', 'OWNER', 'OWNER_COUNTRY']:\n",
    "            unified[col] = unified[col].astype(str).str.strip()\n",
    "            unified[col] = unified[col].replace(['nan', 'None', '', 'NaN'], np.nan)\n",
    "        \n",
    "        return unified\n",
    "\n",
    "# Run integration\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA INTEGRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "integrator = ShipbreakingIntegrator()\n",
    "df = integrator.integrate(dataframes)\n",
    "\n",
    "print(f\"\\nUnified dataset: {len(df):,} records\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nRecords per year:\")\n",
    "print(df['YEAR'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check owner data coverage\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OWNER DATA COVERAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "owner_coverage = df.groupby('YEAR').agg({\n",
    "    'OWNER': lambda x: x.notna().sum(),\n",
    "    'OWNER_COUNTRY': lambda x: x.notna().sum(),\n",
    "    'NAME': 'count'\n",
    "}).rename(columns={'NAME': 'TOTAL'})\n",
    "\n",
    "owner_coverage['OWNER_PCT'] = (owner_coverage['OWNER'] / owner_coverage['TOTAL'] * 100).round(1)\n",
    "owner_coverage['OWNER_COUNTRY_PCT'] = (owner_coverage['OWNER_COUNTRY'] / owner_coverage['TOTAL'] * 100).round(1)\n",
    "\n",
    "print(\"\\nOwner data availability by year:\")\n",
    "print(owner_coverage)\n",
    "\n",
    "print(f\"\\nTotal records with OWNER: {df['OWNER'].notna().sum():,} ({df['OWNER'].notna().sum()/len(df)*100:.1f}%)\")\n",
    "print(f\"Total records with OWNER_COUNTRY: {df['OWNER_COUNTRY'].notna().sum():,} ({df['OWNER_COUNTRY'].notna().sum()/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Setup\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset: {len(df):,} records\")\n",
    "print(f\"Years: {int(df['YEAR'].min())} - {int(df['YEAR'].max())}\")\n",
    "\n",
    "print(\"\\nMissing data summary:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing': missing,\n",
    "    'Pct': missing_pct\n",
    "})\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 1: Ships Dismantled Per Year\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 1: SHIPS DISMANTLED PER YEAR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "yearly_counts = df['YEAR'].value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.bar(yearly_counts.index, yearly_counts.values, color='steelblue', alpha=0.8, edgecolor='black')\n",
    "ax.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Ships', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Ships Dismantled Per Year (2012-2024)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, count in zip(bars, yearly_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20, \n",
    "            str(count), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal ships dismantled: {len(df):,}\")\n",
    "print(f\"Average per year: {yearly_counts.mean():.0f}\")\n",
    "print(f\"Peak: {int(yearly_counts.idxmax())} ({yearly_counts.max()} ships)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 2: Geographic Distribution (Destination Countries)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 2: DESTINATION COUNTRIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "country_counts = df['COUNTRY'].value_counts().head(10)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(country_counts)))\n",
    "ax1.barh(range(len(country_counts)), country_counts.values, color=colors, edgecolor='black')\n",
    "ax1.set_yticks(range(len(country_counts)))\n",
    "ax1.set_yticklabels(country_counts.index)\n",
    "ax1.set_xlabel('Number of Ships', fontweight='bold')\n",
    "ax1.set_title('Top 10 Ship Dismantling Destinations', fontweight='bold', fontsize=14)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "for i, (count, pct) in enumerate(zip(country_counts.values, country_counts.values/len(df)*100)):\n",
    "    ax1.text(count + 50, i, f'{count:,} ({pct:.1f}%)', va='center', fontsize=10)\n",
    "\n",
    "# Pie chart - South Asia vs Others\n",
    "south_asia = ['India', 'Bangladesh', 'Pakistan']\n",
    "south_asia_count = df[df['COUNTRY'].isin(south_asia)].shape[0]\n",
    "other_count = len(df) - south_asia_count\n",
    "\n",
    "ax2.pie([south_asia_count, other_count], \n",
    "        labels=['South Asia\\n(India, Bangladesh, Pakistan)', 'Rest of World'],\n",
    "        autopct='%1.1f%%', colors=['#d62728', '#1f77b4'], startangle=90,\n",
    "        explode=[0.05, 0], textprops={'fontsize': 12})\n",
    "ax2.set_title('Regional Distribution of Ship Breaking', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSouth Asian yards handle {south_asia_count/len(df)*100:.1f}% of global ship breaking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 3: Ship Types and Ages\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 3: SHIP CHARACTERISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ship types\n",
    "type_counts = df['TYPE'].value_counts().head(10)\n",
    "\n",
    "# Age calculation\n",
    "df['AGE'] = df['YEAR'] - df['BUILT']\n",
    "df_age = df[(df['AGE'] >= 0) & (df['AGE'] <= 80)]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Ship types\n",
    "ax1.barh(range(len(type_counts)), type_counts.values, color='teal', alpha=0.8)\n",
    "ax1.set_yticks(range(len(type_counts)))\n",
    "ax1.set_yticklabels(type_counts.index)\n",
    "ax1.set_xlabel('Number of Ships', fontweight='bold')\n",
    "ax1.set_title('Most Common Ship Types Dismantled', fontweight='bold', fontsize=14)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Age distribution\n",
    "ax2.hist(df_age['AGE'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(df_age['AGE'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "            label=f\"Mean: {df_age['AGE'].mean():.1f} years\")\n",
    "ax2.axvline(df_age['AGE'].median(), color='blue', linestyle='--', linewidth=2,\n",
    "            label=f\"Median: {df_age['AGE'].median():.1f} years\")\n",
    "ax2.set_xlabel('Age at Dismantling (years)', fontweight='bold')\n",
    "ax2.set_ylabel('Number of Ships', fontweight='bold')\n",
    "ax2.set_title('Ship Age at Dismantling', fontweight='bold', fontsize=14)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage ship age at dismantling: {df_age['AGE'].mean():.1f} years\")\n",
    "print(f\"Most common ship type: {type_counts.index[0]} ({type_counts.iloc[0]:,} ships)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OWNER ANALYSIS - BENEFICIAL OWNERS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 4: BENEFICIAL OWNERS OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter to records with owner data\n",
    "df_owners = df[df['OWNER'].notna()].copy()\n",
    "print(f\"\\nRecords with owner data: {len(df_owners):,} ({len(df_owners)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Top beneficial owners\n",
    "top_owners = df_owners['OWNER'].value_counts().head(20)\n",
    "\n",
    "print(\"\\nTop 20 Beneficial Owners by Volume:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (owner, count) in enumerate(top_owners.items(), 1):\n",
    "    print(f\"{i:2d}. {owner[:50]:50s} {count:4d} ships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 5: Owner Countries\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 5: OWNER COUNTRIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_owner_country = df[df['OWNER_COUNTRY'].notna()].copy()\n",
    "print(f\"\\nRecords with owner country data: {len(df_owner_country):,}\")\n",
    "\n",
    "owner_country_counts = df_owner_country['OWNER_COUNTRY'].value_counts().head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "colors = plt.cm.Blues(np.linspace(0.3, 0.9, len(owner_country_counts)))\n",
    "bars = ax.barh(range(len(owner_country_counts)), owner_country_counts.values, color=colors, edgecolor='black')\n",
    "ax.set_yticks(range(len(owner_country_counts)))\n",
    "ax.set_yticklabels(owner_country_counts.index)\n",
    "ax.set_xlabel('Number of Ships Owned', fontweight='bold')\n",
    "ax.set_title('Beneficial Owner Countries', fontweight='bold', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "for i, count in enumerate(owner_country_counts.values):\n",
    "    pct = count / len(df_owner_country) * 100\n",
    "    ax.text(count + 20, i, f'{count:,} ({pct:.1f}%)', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop owner countries:\")\n",
    "for country, count in owner_country_counts.head(10).items():\n",
    "    print(f\"  {country}: {count:,} ships ({count/len(df_owner_country)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 6: Owner Country to Destination Country Flow\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 6: OWNER COUNTRY TO DESTINATION FLOW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter to records with both owner country and destination\n",
    "df_flow = df[(df['OWNER_COUNTRY'].notna()) & (df['COUNTRY'].notna())].copy()\n",
    "print(f\"\\nRecords with both owner country and destination: {len(df_flow):,}\")\n",
    "\n",
    "# Create flow matrix\n",
    "flow = df_flow.groupby(['OWNER_COUNTRY', 'COUNTRY']).size().reset_index(name='COUNT')\n",
    "flow_pivot = flow.pivot_table(index='OWNER_COUNTRY', columns='COUNTRY', values='COUNT', fill_value=0)\n",
    "\n",
    "# Top owner countries sending to South Asia\n",
    "south_asia_dest = ['India', 'Bangladesh', 'Pakistan']\n",
    "south_asia_cols = [c for c in flow_pivot.columns if c in south_asia_dest]\n",
    "\n",
    "if south_asia_cols:\n",
    "    flow_pivot['TO_SOUTH_ASIA'] = flow_pivot[south_asia_cols].sum(axis=1)\n",
    "    flow_pivot['TOTAL'] = flow_pivot.drop(columns=['TO_SOUTH_ASIA']).sum(axis=1)\n",
    "    flow_pivot['SOUTH_ASIA_PCT'] = (flow_pivot['TO_SOUTH_ASIA'] / flow_pivot['TOTAL'] * 100).round(1)\n",
    "    \n",
    "    top_to_south_asia = flow_pivot[['TO_SOUTH_ASIA', 'TOTAL', 'SOUTH_ASIA_PCT']].sort_values('TO_SOUTH_ASIA', ascending=False).head(15)\n",
    "    \n",
    "    print(\"\\nOwner countries by ships sent to South Asian yards:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Owner Country':<25} {'To South Asia':>15} {'Total':>10} {'%':>10}\")\n",
    "    print(\"-\" * 70)\n",
    "    for country, row in top_to_south_asia.iterrows():\n",
    "        print(f\"{country:<25} {int(row['TO_SOUTH_ASIA']):>15,} {int(row['TOTAL']):>10,} {row['SOUTH_ASIA_PCT']:>9.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 7: European Owners Analysis\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 7: EUROPEAN OWNER PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# EU/European countries\n",
    "european_countries = [\n",
    "    'Germany', 'Greece', 'Norway', 'Denmark', 'Netherlands', 'Belgium',\n",
    "    'United Kingdom', 'UK', 'France', 'Italy', 'Sweden', 'Finland',\n",
    "    'Switzerland', 'Austria', 'Poland', 'Spain', 'Portugal', 'Cyprus',\n",
    "    'Malta', 'Luxembourg', 'Ireland'\n",
    "]\n",
    "\n",
    "df_european = df_flow[df_flow['OWNER_COUNTRY'].isin(european_countries)].copy()\n",
    "print(f\"\\nShips owned by European entities: {len(df_european):,}\")\n",
    "\n",
    "# Where do European-owned ships go?\n",
    "european_destinations = df_european['COUNTRY'].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Which European countries own the most scrapped ships\n",
    "euro_owners = df_european['OWNER_COUNTRY'].value_counts().head(10)\n",
    "ax1.barh(range(len(euro_owners)), euro_owners.values, color='navy', alpha=0.8)\n",
    "ax1.set_yticks(range(len(euro_owners)))\n",
    "ax1.set_yticklabels(euro_owners.index)\n",
    "ax1.set_xlabel('Number of Ships', fontweight='bold')\n",
    "ax1.set_title('European Countries by Ships Scrapped', fontweight='bold', fontsize=14)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Where do European ships end up?\n",
    "euro_dest = european_destinations.head(8)\n",
    "colors = ['#d62728' if d in south_asia_dest else '#1f77b4' for d in euro_dest.index]\n",
    "ax2.barh(range(len(euro_dest)), euro_dest.values, color=colors, alpha=0.8)\n",
    "ax2.set_yticks(range(len(euro_dest)))\n",
    "ax2.set_yticklabels(euro_dest.index)\n",
    "ax2.set_xlabel('Number of Ships', fontweight='bold')\n",
    "ax2.set_title('Destinations for European-Owned Ships\\n(Red = South Asia)', fontweight='bold', fontsize=14)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate percentage going to South Asia\n",
    "euro_to_south_asia = df_european[df_european['COUNTRY'].isin(south_asia_dest)].shape[0]\n",
    "print(f\"\\nEuropean-owned ships sent to South Asian yards:\")\n",
    "print(f\"  {euro_to_south_asia:,} out of {len(df_european):,} ({euro_to_south_asia/len(df_european)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 8: Companies of Interest - High Volume\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 8: COMPANIES OF INTEREST - HIGH VOLUME\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThese beneficial owners have sent the most ships to dismantling.\")\n",
    "print(\"This is provided for research and transparency purposes.\")\n",
    "\n",
    "# Top 10 owners with their preferred destinations\n",
    "top_10_owners = df_owners['OWNER'].value_counts().head(10).index.tolist()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "for owner in top_10_owners:\n",
    "    owner_data = df_owners[df_owners['OWNER'] == owner]\n",
    "    total = len(owner_data)\n",
    "    destinations = owner_data['COUNTRY'].value_counts().head(3)\n",
    "    \n",
    "    owner_country = owner_data['OWNER_COUNTRY'].mode()\n",
    "    owner_country_str = owner_country.iloc[0] if len(owner_country) > 0 else 'Unknown'\n",
    "    \n",
    "    print(f\"\\n{owner[:60]}\")\n",
    "    print(f\"  Based in: {owner_country_str}\")\n",
    "    print(f\"  Ships scrapped: {total}\")\n",
    "    print(f\"  Top destinations:\")\n",
    "    for dest, count in destinations.items():\n",
    "        pct = count/total*100\n",
    "        print(f\"    - {dest}: {count} ({pct:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 9: Companies of Interest - Tail Analysis (Bottom 50)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 9: COMPANIES OF INTEREST - TAIL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThese are beneficial owners appearing only once or twice in the dataset.\")\n",
    "print(\"Single-ship owners may warrant further review for research purposes.\")\n",
    "print(\"This can indicate shell companies or last-minute ownership transfers.\")\n",
    "\n",
    "# Get owners with only 1-2 ships\n",
    "owner_counts = df_owners['OWNER'].value_counts()\n",
    "single_ship_owners = owner_counts[owner_counts <= 2]\n",
    "\n",
    "print(f\"\\nTotal beneficial owners in dataset: {len(owner_counts):,}\")\n",
    "print(f\"Owners with only 1-2 ships: {len(single_ship_owners):,} ({len(single_ship_owners)/len(owner_counts)*100:.1f}%)\")\n",
    "\n",
    "# Show last 50 (tail)\n",
    "tail_50 = owner_counts.tail(50)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"LAST 50 BENEFICIAL OWNERS (by frequency):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'#':<4} {'Beneficial Owner':<50} {'Ships':>6}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (owner, count) in enumerate(tail_50.items(), 1):\n",
    "    print(f\"{i:<4} {owner[:50]:<50} {count:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 10: Deep Dive on Tail Owners\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 10: TAIL OWNER DETAILS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDetailed view of the last 50 beneficial owners.\")\n",
    "print(\"Includes ship names, destinations, and owner countries.\")\n",
    "\n",
    "# Get the last 50 owners\n",
    "tail_50_names = owner_counts.tail(50).index.tolist()\n",
    "\n",
    "# Get their ship details\n",
    "tail_ships = df_owners[df_owners['OWNER'].isin(tail_50_names)][[\n",
    "    'YEAR', 'NAME', 'TYPE', 'OWNER', 'OWNER_COUNTRY', 'COUNTRY', 'LAST_FLAG'\n",
    "]].sort_values(['OWNER', 'YEAR'])\n",
    "\n",
    "print(f\"\\nShips from tail 50 owners: {len(tail_ships)}\")\n",
    "print(\"\\n\" + \"-\" * 120)\n",
    "\n",
    "# Group by owner and show details\n",
    "for owner in tail_50_names[:25]:  # Show first 25 of the tail\n",
    "    owner_ships = tail_ships[tail_ships['OWNER'] == owner]\n",
    "    print(f\"\\nOWNER: {owner}\")\n",
    "    for _, ship in owner_ships.iterrows():\n",
    "        print(f\"  {int(ship['YEAR'])} | {str(ship['NAME'])[:30]:<30} | {str(ship['TYPE'])[:15]:<15} | Flag: {str(ship['LAST_FLAG'])[:15]:<15} | Dest: {ship['COUNTRY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 11: Tail Owner Statistics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 11: TAIL OWNER PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Statistics on single-ship owners\n",
    "single_ship_data = df_owners[df_owners['OWNER'].isin(single_ship_owners.index)]\n",
    "\n",
    "print(f\"\\nAnalyzing {len(single_ship_data):,} ships from {len(single_ship_owners):,} single/dual-ship owners\")\n",
    "\n",
    "# Where do single-ship owner vessels go?\n",
    "single_dest = single_ship_data['COUNTRY'].value_counts().head(10)\n",
    "single_to_sa = single_ship_data[single_ship_data['COUNTRY'].isin(south_asia_dest)].shape[0]\n",
    "\n",
    "print(f\"\\nDestinations for single-ship owner vessels:\")\n",
    "for dest, count in single_dest.items():\n",
    "    pct = count / len(single_ship_data) * 100\n",
    "    print(f\"  {dest}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nSouth Asia total: {single_to_sa:,} ({single_to_sa/len(single_ship_data)*100:.1f}%)\")\n",
    "\n",
    "# Owner countries of single-ship owners\n",
    "single_owner_countries = single_ship_data['OWNER_COUNTRY'].value_counts().head(10)\n",
    "print(f\"\\nOwner countries (single-ship owners):\")\n",
    "for country, count in single_owner_countries.items():\n",
    "    print(f\"  {country}: {count:,}\")\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Destinations\n",
    "colors1 = ['#d62728' if d in south_asia_dest else '#1f77b4' for d in single_dest.index]\n",
    "ax1.barh(range(len(single_dest)), single_dest.values, color=colors1, alpha=0.8)\n",
    "ax1.set_yticks(range(len(single_dest)))\n",
    "ax1.set_yticklabels(single_dest.index)\n",
    "ax1.set_xlabel('Number of Ships', fontweight='bold')\n",
    "ax1.set_title('Where Single-Ship Owners Send Vessels\\n(Red = South Asia)', fontweight='bold', fontsize=14)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Owner countries\n",
    "ax2.barh(range(len(single_owner_countries)), single_owner_countries.values, color='teal', alpha=0.8)\n",
    "ax2.set_yticks(range(len(single_owner_countries)))\n",
    "ax2.set_yticklabels(single_owner_countries.index)\n",
    "ax2.set_xlabel('Number of Ships', fontweight='bold')\n",
    "ax2.set_title('Single-Ship Owner Countries', fontweight='bold', fontsize=14)\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS 12: Trends Over Time\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS 12: TRENDS OVER TIME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# South Asia percentage by year\n",
    "yearly_south_asia = df.groupby('YEAR').apply(\n",
    "    lambda x: (x['COUNTRY'].isin(south_asia_dest).sum() / len(x) * 100) if len(x) > 0 else 0\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# South Asia percentage over time\n",
    "ax1.plot(yearly_south_asia.index, yearly_south_asia.values, marker='o', linewidth=2, markersize=8, color='darkred')\n",
    "ax1.fill_between(yearly_south_asia.index, yearly_south_asia.values, alpha=0.3, color='red')\n",
    "ax1.set_xlabel('Year', fontweight='bold')\n",
    "ax1.set_ylabel('% to South Asian Yards', fontweight='bold')\n",
    "ax1.set_title('Share of Ships Going to South Asian Yards', fontweight='bold', fontsize=14)\n",
    "ax1.set_ylim([0, 100])\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.axhline(y=80, color='gray', linestyle='--', alpha=0.5, label='80% line')\n",
    "\n",
    "# Top destinations over time (stacked area)\n",
    "top_dest = df['COUNTRY'].value_counts().head(5).index.tolist()\n",
    "yearly_dest = df[df['COUNTRY'].isin(top_dest)].groupby(['YEAR', 'COUNTRY']).size().unstack(fill_value=0)\n",
    "\n",
    "yearly_dest.plot(kind='area', stacked=True, ax=ax2, alpha=0.8)\n",
    "ax2.set_xlabel('Year', fontweight='bold')\n",
    "ax2.set_ylabel('Number of Ships', fontweight='bold')\n",
    "ax2.set_title('Top 5 Destinations Over Time', fontweight='bold', fontsize=14)\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSouth Asia share: {yearly_south_asia.iloc[0]:.1f}% in {int(yearly_south_asia.index[0])} → {yearly_south_asia.iloc[-1]:.1f}% in {int(yearly_south_asia.index[-1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "south_asia_pct = df[df['COUNTRY'].isin(south_asia_dest)].shape[0] / len(df) * 100\n",
    "\n",
    "print(f\"\"\"\n",
    "SHIP BREAKING DATA ANALYSIS\n",
    "===========================\n",
    "\n",
    "DATASET OVERVIEW:\n",
    "- {len(df):,} ships dismantled globally (2012-2024)\n",
    "- Average ship age at scrapping: {df_age['AGE'].mean():.0f} years\n",
    "- Most common type: {df['TYPE'].value_counts().index[0]}\n",
    "\n",
    "GEOGRAPHIC PATTERNS:\n",
    "- {south_asia_pct:.1f}% of ships go to South Asian yards\n",
    "- Top destination: {df['COUNTRY'].value_counts().index[0]}\n",
    "\n",
    "BENEFICIAL OWNER ANALYSIS:\n",
    "- Owner data available for {df['OWNER'].notna().sum():,} ships ({df['OWNER'].notna().sum()/len(df)*100:.1f}%)\n",
    "- Total unique owners: {df_owners['OWNER'].nunique():,}\n",
    "- Single/dual-ship owners: {len(single_ship_owners):,} ({len(single_ship_owners)/len(owner_counts)*100:.1f}%)\n",
    "\n",
    "KEY OBSERVATIONS:\n",
    "- High concentration of ships going to a few destination countries\n",
    "- Large number of single-ship owners may indicate ownership transfers\n",
    "- Owner country data enables tracking of cross-border ship flows\n",
    "\n",
    "This analysis is provided for research and transparency purposes.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
